{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:28:09.576992Z",
     "start_time": "2020-08-04T14:27:50.805928Z"
    }
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import io\n",
    "import sqlite3\n",
    "import requests\n",
    "import sys\n",
    "import config\n",
    "import tweepy\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import spacy\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from spacy import displacy\n",
    "from bs4 import BeautifulSoup\n",
    "from streamlit import caching\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from plotly.subplots import make_subplots\n",
    "from nltk import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "from wordcloud import ImageColorGenerator\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:36:05.969387Z",
     "start_time": "2020-08-04T14:36:05.957417Z"
    }
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'ix6w1FxQ1TdcApgeSvV8bxxJO'\n",
    "CONSUMER_SECRET = '6ktBJ2Hs5YRv5bDELerh8izdq9MMUIUluu23iVi0Bv8jXHxLAb'\n",
    "ACCESS_TOKEN = '1228366543731544064-aG7SEQkWkzSvurHTFAgYSQ7iDELnai'\n",
    "ACCESS_TOKEN_SECRET = 'UoP6UvP8BskhcEjhK6uvHzj9q0EaIavPHk6nE20fIWE33'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:36:37.929405Z",
     "start_time": "2020-08-04T14:36:36.922022Z"
    }
   },
   "outputs": [],
   "source": [
    "consumer_key = CONSUMER_KEY\n",
    "consumer_secret = CONSUMER_SECRET\n",
    "access_token = ACCESS_TOKEN\n",
    "access_token_secret = ACCESS_TOKEN_SECRET\n",
    "\n",
    "\n",
    "# Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "\n",
    "def get_traders_names():\n",
    "    headers = {\n",
    "        \"User-Agent\":\n",
    "        \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Mobile Safari/537.36\"}\n",
    "    url = \"https://www.forexcrunch.com/60-top-forex-twitter-accounts/\"\n",
    "    res = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    table = soup.find(name=\"ol\")\n",
    "    traders = []\n",
    "    for element in table.find_all(name=\"li\"):\n",
    "        trader = element.find(name=\"a\").text.replace(\"@\", \"\")\n",
    "        traders.append(trader)\n",
    "    return traders\n",
    "traders = get_traders_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:37:48.271625Z",
     "start_time": "2020-08-04T14:37:48.256660Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_trader_twitter():\n",
    "    traders = get_traders_names()\n",
    "    api = TwitterClient().get_twitter_client_api()\n",
    "    tweet_analyzer = TweetAnalyzer()\n",
    "    df = pd.DataFrame()\n",
    "    for trader in tqdm(traders):\n",
    "        try:\n",
    "            tweets = api.user_timeline(screen_name=trader, count=100)\n",
    "            df_trader = tweet_analyzer.tweets_to_dataframe(tweets)\n",
    "            df = pd.concat([df, df_trader], axis=0)\n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:37:56.762831Z",
     "start_time": "2020-08-04T14:37:56.750864Z"
    }
   },
   "outputs": [],
   "source": [
    "def insert_into_db():\n",
    "    df = get_all_trader_twitter()\n",
    "    print(df.shape)\n",
    "    conn = sqlite3.connect('twitter.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"DROP TABLE IF EXISTS TEMPTRADER\"\"\")\n",
    "    df.to_sql(name='TEMPTRADER', con=conn, if_exists=\"replace\", index=False)\n",
    "    cursor.execute(\n",
    "        '''\n",
    "        INSERT INTO TRADER\n",
    "        SELECT A.* FROM TEMPTRADER A\n",
    "        LEFT JOIN TRADER B\n",
    "        ON A.id=B.id\n",
    "        WHERE B.id IS NULL\n",
    "        ''')\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:41:06.430388Z",
     "start_time": "2020-08-04T14:41:06.359253Z"
    }
   },
   "outputs": [],
   "source": [
    "#@st.cache(persist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:42:04.406089Z",
     "start_time": "2020-08-04T14:42:04.400105Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_from_db():\n",
    "    conn = sqlite3.connect('twitter.db')\n",
    "    df = pd.read_sql_query(\"SELECT * FROM TRADER\", con=conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:41:11.830568Z",
     "start_time": "2020-08-04T14:41:11.818602Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tweets(user_name, tweet_count):\n",
    "    tweets_list = []\n",
    "    img_url = \"\"\n",
    "    name = \"\"\n",
    "    try:\n",
    "        for tweet in api.user_timeline(\n",
    "            id=user_name, count=tweet_count, tweet_mode=\"extended\"):\n",
    "            tweets_dict = {}\n",
    "            tweets_dict[\"date_created\"] = tweet.created_at\n",
    "            tweets_dict[\"tweet_id\"] = tweet.id\n",
    "            tweets_dict[\"tweet\"] = tweet.full_text\n",
    "            tweets_list.append(tweets_dict)\n",
    "\n",
    "        img_url = tweet.user.profile_image_url\n",
    "        name = tweet.user.name\n",
    "        screen_name = tweet.user.screen_name\n",
    "        desc = tweet.user.description\n",
    "\n",
    "    except BaseException as e:\n",
    "        st.exception(\n",
    "            \"Failed to retrieve the Tweets. Please check if the twitter handle is correct.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    return tweets_list, img_url, name, screen_name, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:38:28.389490Z",
     "start_time": "2020-08-04T14:38:28.374528Z"
    }
   },
   "outputs": [],
   "source": [
    "def prep_data(tweet):\n",
    "    return null\n",
    "\n",
    "\n",
    "def wordcloud(clean_tweet):\n",
    "\tfont_path = \"./Scribble Note DEMO.otf\"\n",
    "\textra_stopwords = [\"The\", \"It\", \"it\", \"in\", \"In\", \"wh\", \"yo\"]\n",
    "\twordcloud_words = \" \".join(clean_tweet)\n",
    "\twordcloud = WordCloud(\n",
    "\t\tstopwords=extra_stopwords, height=300, width=500,\n",
    "\t\tbackground_color=\"white\", random_state=100, font_path=font_path\n",
    "\t).generate(wordcloud_words)\n",
    "\tplt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "\tplt.axis(\"off\")\n",
    "\tplt.savefig(\"wordcloud.jpg\")\n",
    "\timg = Image.open(\"wordcloud.jpg\")\n",
    "\treturn img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(tweet):\n",
    "    return TextBlob(tweet).sentiment.polarity\n",
    "\n",
    "\n",
    "def get_analysis(polarity_score):\n",
    "    if polarity_score < 0:\n",
    "        return \"Negative\"\n",
    "    elif polarity_score == 0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectivity(tweet):\n",
    "    return TextBlob(tweet).sentiment.subjectivity\n",
    "\n",
    "\n",
    "def get_sub_analysis(subjectivity_score):\n",
    "    if subjectivity_score <= 0.5:\n",
    "        return \"Objective\"\n",
    "    else:\n",
    "        return \"Subjective\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:39:20.302456Z",
     "start_time": "2020-08-04T14:39:20.250595Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_sentiments(tweet_df):\n",
    "    sentiment_df = (\n",
    "        pd.DataFrame(tweet_df[\"sentiment\"].value_counts())\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"sentiment_name\"}))\n",
    "    fig = go.Figure(\n",
    "        [go.Bar(x=sentiment_df[\"sentiment_name\"], y=sentiment_df[\"sentiment\"])])\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(showgrid=False),\n",
    "        yaxis=dict(showgrid=False, title=\"Sentiment Score\"),\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_subjectivity(tweet_df):\n",
    "    colors = [\"teal\", \"turquoise\"]\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Pie(\n",
    "                values=tweet_df[\"subjectivity\"].values,\n",
    "                labels=tweet_df[\"sub_obj\"].values,)])\n",
    "    fig.update_traces(\n",
    "        hoverinfo=\"label\",\n",
    "        textinfo=\"percent\",\n",
    "        textfont_size=18,\n",
    "        marker=dict(colors=colors, line=dict(color=\"#000000\", width=2)),)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def polarity_plot(polarity_df):\n",
    "    z = np.sort(np.asarray(polarity_df))\n",
    "    plt.figure(figsize= (15, 10))\n",
    "    fig = make_subplots(\n",
    "        rows=2,\n",
    "        cols=1,\n",
    "        subplot_titles=(\"Heatmap of user sentiments(Polarity)\",\n",
    "                        \"Sentiment Distribution(Polarity)\"))\n",
    "    # Heatmap\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        z= [z],\n",
    "        type='heatmap',\n",
    "        colorscale='Viridis', zmax=1, zmin=-1,\n",
    "        showscale=False), row=1, col=1)\n",
    "\n",
    "    # Histogram\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x= polarity_df,\n",
    "        name='polarity',\n",
    "        xbins=dict(start=-1.0, end=1.0)),row=2, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=500,\n",
    "        title_x=0.5,\n",
    "        title_text='Sentiment Distribution')\n",
    "    fig.update_traces(opacity=0.75)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:39:34.312660Z",
     "start_time": "2020-08-04T14:39:34.298698Z"
    }
   },
   "outputs": [],
   "source": [
    "def subjectivity_plot(subjectivity_df):\n",
    "    z = np.sort(np.asarray(subjectivity_df))\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=(\n",
    "            \"Heatmap of user sentiments(Subjectivity)\",\n",
    "            \"Sentiment Distribution(Subjectivity)\"))\n",
    "    # Heatmap\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        z=[z],\n",
    "        type='heatmap', name='subjectivity',\n",
    "        colorscale='Viridis', zmax=1, zmin=-1,\n",
    "        showscale=False), row=1, col=1)\n",
    "\n",
    "    # Histogram\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=subjectivity_df,\n",
    "        name='subjectivity(0-1)',\n",
    "        xbins=dict(start=0, end=1.0)), row=2, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=500,\n",
    "        title_x=0.5,\n",
    "        title_text='Sentiment Distribution')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frequency(ax, data):\n",
    "    ncount = len(data)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.yaxis.tick_left()\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.yaxis.set_label_position('right')\n",
    "    ax2.yaxis.set_label_position('left')\n",
    "    ax2.set_ylabel('Frequency [%]')\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.grid(None)\n",
    "\n",
    "def upper_rugplot(data, height=.05, ax=None, **kwargs):\n",
    "    from matplotlib.collections import LineCollection\n",
    "    ax = ax or plt.gca()\n",
    "    kwargs.setdefault(\"linewidth\", 1)\n",
    "    segs = np.stack((np.c_[data, data],\n",
    "                     np.c_[np.ones_like(data), np.ones_like(data)-height]),\n",
    "                    axis=-1)\n",
    "    lc = LineCollection(segs, transform=ax.get_xaxis_transform(), **kwargs)\n",
    "    ax.add_collection(lc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_favorite_count(df):\n",
    "\tplt.figure(figsize=(16, 5))\n",
    "\tfig = sns.countplot(\"favorite_count\", data=df, palette=sns.color_palette(\"hls\", 8))\n",
    "\tplt.title(\"Favorite Count\")\n",
    "\tplt.xlim((-0.5, 9.5))\n",
    "\tplt.grid(axis=\"y\")\n",
    "\tadd_frequency(fig, df)\n",
    "\treturn fig\n",
    "\n",
    "\n",
    "def select_top_k_retweeted_tweets(df, k=5, print_result=False):\n",
    "    tweet_df = df.sort_values(by='retweet_count', ascending=False)\n",
    "    tweet_df = tweet_df.reset_index(drop=True)\n",
    "    top_k_retweeted_tweets = []\n",
    "    for i in range(k):\n",
    "        top_k_retweeted_tweets.append(tweet_df['tweet'].iloc[i])\n",
    "    if print_result:\n",
    "        # Total tweets\n",
    "        print('Total tweets this period:', len(df.index))\n",
    "        print('='*30, \"\\n\")\n",
    "\n",
    "        # Retweets\n",
    "        print('Mean retweets:', round(tweet_df['retweet_count'].mean(), 2), '\\n')\n",
    "        print('Top 5 retweeted tweets:')\n",
    "        print('-'*25)\n",
    "        for i in range(5):\n",
    "            print(\"#{}: \".format(i+1), tweet_df['retweet_count'].iloc[i], \"\\n\", tweet_df['tweet'].iloc[i], \"\\n\")\n",
    "        print('\\n')\n",
    "\n",
    "    return top_k_retweeted_tweets\n",
    "\n",
    "def select_top_k_liked_tweets(df, k=5, print_result=False):\n",
    "    tweet_df = df.sort_values(by='favorite_count', ascending=False)\n",
    "    tweet_df = tweet_df.reset_index(drop=True)\n",
    "    top_k_liked_tweets = []\n",
    "    for i in range(k):\n",
    "        top_k_liked_tweets.append(tweet_df['tweet'].iloc[i])\n",
    "    if print_result:\n",
    "        # Total tweets\n",
    "        print('Total tweets this period:', len(df.index))\n",
    "        print('='*30, \"\\n\")\n",
    "\n",
    "        # Likes\n",
    "        print('Mean likes:', round(tweet_df['favorite_count'].mean(), 2), '\\n')\n",
    "        print('Top 5 liked tweets:')\n",
    "        print('-'*25)\n",
    "        for i in range(5):\n",
    "            print(\"#{}: \".format(i+1), tweet_df['favorite_count'].iloc[i], \"\\n\", tweet_df['tweet'].iloc[i], \"\\n\")\n",
    "        print('\\n')\n",
    "\n",
    "    return top_k_liked_tweets\n",
    "\n",
    "\n",
    "def show_entities(text):\n",
    "\timport en_core_web_sm\n",
    "\tnlp = en_core_web_sm.load()\n",
    "\t# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\tdoc = nlp(text)\n",
    "\tcolors = {\"ORG\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "\toptions = {\"ents\": [\"ORG\"], \"colors\": colors}\n",
    "\tdisplacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:40:13.862784Z",
     "start_time": "2020-08-04T14:40:13.785990Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_from_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-ca15a7bf0135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mcaching\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mapp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-ca15a7bf0135>\u001b[0m in \u001b[0;36mapp\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_from_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[0mactivities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Exploratory Data Analysis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Twitter Stream\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Forex Prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Backtesting\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mchoice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msidebar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselectbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Choose Activity\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_from_db' is not defined"
     ]
    }
   ],
   "source": [
    "def eda_on_tweet(user_name, tweet_count):\n",
    "    if user_name != \"\" and tweet_count > 0:\n",
    "\n",
    "        with st.spinner(\"Please Wait!! Analysis is in Progress...\"):\n",
    "            time.sleep(1)\n",
    "\n",
    "        tweets_list, img_url, name, screen_name, desc = get_tweets(\n",
    "            user_name, tweet_count)\n",
    "\n",
    "        # Adding the retrieved tweet data into a dataframe\n",
    "        tweet_df = pd.DataFrame([tweet for tweet in tweets_list])\n",
    "        st.sidebar.success(\"Twitter Handle Details:\")\n",
    "        st.sidebar.markdown(\"Name: \" + name)\n",
    "        st.sidebar.markdown(\"Screen Name: @\" + screen_name)\n",
    "        st.sidebar.markdown(\"Description: \" + desc)\n",
    "\n",
    "        # Calling the function to prep the data\n",
    "        tweet_df[\"clean_tweet\"] = tweet_df[\"tweet\"]\n",
    "\n",
    "        # Calling the function to create sentiment scoring\n",
    "        tweet_df[\"polarity\"] = tweet_df[\"clean_tweet\"].apply(get_polarity)\n",
    "        tweet_df[\"sentiment\"] = tweet_df[\"polarity\"].apply(get_analysis)\n",
    "        tweet_df[\"subjectivity\"] = tweet_df[\"clean_tweet\"].apply(get_subjectivity)\n",
    "        tweet_df[\"sub_obj\"] = tweet_df[\"subjectivity\"].apply(get_sub_analysis)\n",
    "\n",
    "        # Calling the function for plotting the sentiments\n",
    "        senti_fig = plot_sentiments(tweet_df)\n",
    "        st.success(\n",
    "            \"Sentiment Analysis for Twitter Handle @\"\n",
    "            + user_name\n",
    "            + \" based on the last \"\n",
    "            + str(tweet_count)\n",
    "            + \" tweet(s)!!\")\n",
    "        st.plotly_chart(senti_fig, use_container_width=True)\n",
    "\n",
    "        # Calling the function for plotting the subjectivity\n",
    "        subjectivity_fig = plot_subjectivity(tweet_df)\n",
    "\n",
    "        if sum(tweet_df[\"subjectivity\"].values) > 0:\n",
    "            st.success(\n",
    "                \"Tweet Subjectivity vs. Objectivity for Twitter Handle @\"\n",
    "                + user_name\n",
    "                + \" based on the last \"\n",
    "                + str(tweet_count)\n",
    "                + \" tweet(s)!!\")\n",
    "            st.plotly_chart(subjectivity_fig, use_container_width=True)\n",
    "        else:\n",
    "            st.error(\n",
    "                \"Sorry, too few words to analyze for Subjectivity & Objectivity Score. \\\n",
    "                Please increase the tweet count using the slider on the sidebar for better results.\")\n",
    "\n",
    "        # Calling the function to create the word cloud\n",
    "        img = wordcloud(tweet_df[\"clean_tweet\"])\n",
    "        st.success(\n",
    "            \"Word Cloud for Twitter Handle @\"\n",
    "            + user_name\n",
    "            + \" based on the last \"\n",
    "            + str(tweet_count)\n",
    "            + \" tweet(s)!!\")\n",
    "        st.image(img)\n",
    "\n",
    "        # Displaying the latest tweets\n",
    "        st.subheader(\n",
    "            \"Latest Tweets (Max 10 returned if more than 10 selected using the sidebar)!\")\n",
    "        st.markdown(\"*****************************************************************\")\n",
    "        st.success(\"Latest Tweets from the Twitter Handle @\" + user_name)\n",
    "\n",
    "        length = 10 if len(tweet_df) > 10 else len(tweet_df)\n",
    "        for i in range(length):\n",
    "            st.write(\n",
    "                \"Tweet Number: \"\n",
    "                + str(i + 1)\n",
    "                + \", Tweet Date: \"\n",
    "                + str(tweet_df[\"date_created\"][i]))\n",
    "            st.info(tweet_df[\"tweet\"][i])\n",
    "    else:\n",
    "        st.info(\n",
    "            \":point_left: Enter the Twitter Handle & Number of Tweets to Analyze on the SideBar :point_left:\")\n",
    "\n",
    "\n",
    "def twitter_stream(df, retweeted_k=5, liked_k=5):\n",
    "\tst.markdown(\"## Top 5 retweeted tweets\")\n",
    "\ttop_5_retweeted_tweets = select_top_k_retweeted_tweets(df, k=retweeted_k, print_result=False)\n",
    "\tfor i, tweet in enumerate(top_5_retweeted_tweets):\n",
    "\t\tst.markdown(\"### Top {}:\".format(i+1))\n",
    "\t\tst.markdown(tweet)\n",
    "\tst.markdown(\"## Top 5 liked tweets\")\n",
    "\ttop_5_liked_tweets = select_top_k_liked_tweets(df, k=liked_k, print_result=False)\n",
    "\tfor i, tweet in enumerate(top_5_liked_tweets):\n",
    "\t\tst.markdown(\"### Top {}:\".format(i+1))\n",
    "\t\tst.markdown(tweet)\n",
    "\n",
    "\n",
    "def app():\n",
    "\tdf = read_from_db()\n",
    "\tactivities = [\"Exploratory Data Analysis\", \"Twitter Stream\", \"Forex Prediction\", \"Backtesting\"]\n",
    "\tchoice = st.sidebar.selectbox(\"Choose Activity\", activities)\n",
    "\n",
    "\tif choice == \"Exploratory Data Analysis\":\n",
    "\t\t# Basic info\n",
    "\t\tst.sidebar.header(\"Enter the Details Here!!\")\n",
    "\t\tuser_name = st.sidebar.text_area(r\"Enter the Twitter Handle without @\")\n",
    "\t\ttweet_count = st.sidebar.slider(\n",
    "\t\t\tr\"Select the number of Latest Tweets to Analyze\", 0, 50, 1)\n",
    "\n",
    "\t\tst.sidebar.markdown(\n",
    "\t\t\t\"#### Press Ctrl+Enter or Use the Slider to initiate the analysis.\")\n",
    "\t\tst.sidebar.markdown(\n",
    "\t\t\t\"*****************************************************************\")\n",
    "\n",
    "\t\tst.markdown(\"\"\"## Made With ML Incubator \"\"\")\n",
    "\t\tst.markdown(\"\"\"# Twitter Sentiment Analysis\"\"\")\n",
    "\t\tst.write(\n",
    "\t\t\t\"This app analyzes the Twitter tweets and returns the most commonly used words, \\\n",
    "\t\t\tassociated sentiments and the subjectivity score!! Note that Private account or \\\n",
    "\t\t\tProtected Tweets will not be accessible through this app.\")\n",
    "\t\tst.write(\n",
    "\t\t\t\":bird: All results are based on the number of Latest Tweets selected on the \\\n",
    "\t\t\tSidebar. :point_left:\")\n",
    "\n",
    "\t\teda_on_tweet(user_name, tweet_count)\n",
    "\n",
    "\tif choice == \"Twitter Stream\":\n",
    "\t\tretweeted_k = st.sidebar.slider(r\"Select top k retweeted tweets\", 0, 10, 1)\n",
    "\t\tliked_k = st.sidebar.slider(r\"Select top k liked tweets\", 0, 10, 1)\n",
    "\t\ttwitter_stream(df, retweeted_k=retweeted_k, liked_k=liked_k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    caching.clear_cache()\n",
    "    st.empty()\n",
    "    app()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
